{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "osQ2CNxt9-nG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install optimum[onnxruntime] transformers git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Whisper to ONNX"
      ],
      "metadata": {
        "id": "F1sDk1ld-PUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from optimum.onnxruntime import ORTModelForSpeechSeq2Seq\n",
        "from transformers import (\n",
        "    set_seed,\n",
        "    AutoProcessor\n",
        ")\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "# Export vanilla & optimized onnx model\n",
        "def export_vanilla_optimized_onnx(model_checkpoint):\n",
        "    set_seed(SEED)\n",
        "    processor = AutoProcessor.from_pretrained(model_checkpoint)\n",
        "\n",
        "    # Vanilla\n",
        "    model = ORTModelForSpeechSeq2Seq.from_pretrained(model_checkpoint, from_transformers=True, use_cache=True)\n",
        "    onnx_path = Path(os.path.join(\"exported_onnx_models/\", model_checkpoint))\n",
        "    model.save_pretrained(onnx_path)\n",
        "    processor.save_pretrained(onnx_path)\n",
        "\n",
        "\n",
        "export_vanilla_optimized_onnx('openai/whisper-tiny')"
      ],
      "metadata": {
        "id": "2369GoOd-Rvd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "S480z9N8_60F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import whisper\n",
        "\n",
        "def transcribe(start_tokens, file, encoder, decoder, tokenizer, skip_special_tokens=True):\n",
        "    def run(seed:np.ndarray, hidden_states)->int:\n",
        "        decoder_output = decoder.run(None, {'input_ids' : np.expand_dims(seed, axis=0), 'encoder_hidden_states': hidden_states})[0]\n",
        "        cleaned = np.argmax(decoder_output, axis=-1)\n",
        "        last_token = cleaned[0,-1]\n",
        "        return last_token\n",
        "    \n",
        "    audio = whisper.load_audio(file)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    mel = whisper.log_mel_spectrogram(audio)\n",
        "    mel = np.expand_dims(mel,0)\n",
        "\n",
        "    hidden_states = encoder.run(None, {'input_features': mel})[0]\n",
        "\n",
        "    tokens = start_tokens\n",
        "    while(True):\n",
        "        last_token = run(tokens, hidden_states)\n",
        "        tokens.append(last_token)\n",
        "        if tokens[-1] == 50257:\n",
        "            return tokenizer.batch_decode(np.expand_dims(tokens, axis=0), skip_special_tokens=skip_special_tokens)[0]"
      ],
      "metadata": {
        "id": "nzZTbaKS_-IM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/datasets/osanseviero/dummy_ja_audio/resolve/main/result.flac"
      ],
      "metadata": {
        "id": "iTqD73PrQd0M",
        "outputId": "4a644606-6dd1-4f78-9fe0-ca11527cc161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-19 21:45:14--  https://huggingface.co/datasets/osanseviero/dummy_ja_audio/resolve/main/result.flac\n",
            "Resolving huggingface.co (huggingface.co)... 3.231.67.228, 54.235.118.239, 2600:1f18:147f:e800:671:b733:ecf3:a585, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.231.67.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/89/0e/890e934652e9c7b9c7c24080b0215138c3c32ab2ceb3f6416f8d1445e4a6adfb/afcdb9f2ca46039a983e43273addcc75bf83ca503452a4e7c908afc2e04dce61?response-content-disposition=attachment%3B%20filename%3D%22result.flac%22&Expires=1674423914&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzg5LzBlLzg5MGU5MzQ2NTJlOWM3YjljN2MyNDA4MGIwMjE1MTM4YzNjMzJhYjJjZWIzZjY0MTZmOGQxNDQ1ZTRhNmFkZmIvYWZjZGI5ZjJjYTQ2MDM5YTk4M2U0MzI3M2FkZGNjNzViZjgzY2E1MDM0NTJhNGU3YzkwOGFmYzJlMDRkY2U2MT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnJlc3VsdC5mbGFjJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjc0NDIzOTE0fX19XX0_&Signature=jNvGiK2-odtpMh0sYLLW4ynZKu7NVBjD38v1ZySxTEzYvTxikBpknlnsf05BJStGzrqVcZFWxLSYv7YGoVA-XTIUn3KjoYBXmVT7juMM-oyHwKY770x6Y0vwPx~UN0yAF5PZZNsaDgQp4Z2njkynG6H~kniBwtLkfjE8kk-WGqFtDW7UumhYrJfLMrJdgSM9ewxWZArX3GAGSXPqgOyOG53xAutpZeDQW20HkGUV8l5zMz3H2H4VBlyNhkpPcq4v7KBz2dBNO7Qm7FoTnWR24hkq1vpDQsn~zOEBUeF3BSOGoZYWVgZBSpE07-oqrNnLAYwDbByPghx8dFdmzb-QEg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-01-19 21:45:14--  https://cdn-lfs.huggingface.co/repos/89/0e/890e934652e9c7b9c7c24080b0215138c3c32ab2ceb3f6416f8d1445e4a6adfb/afcdb9f2ca46039a983e43273addcc75bf83ca503452a4e7c908afc2e04dce61?response-content-disposition=attachment%3B%20filename%3D%22result.flac%22&Expires=1674423914&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzg5LzBlLzg5MGU5MzQ2NTJlOWM3YjljN2MyNDA4MGIwMjE1MTM4YzNjMzJhYjJjZWIzZjY0MTZmOGQxNDQ1ZTRhNmFkZmIvYWZjZGI5ZjJjYTQ2MDM5YTk4M2U0MzI3M2FkZGNjNzViZjgzY2E1MDM0NTJhNGU3YzkwOGFmYzJlMDRkY2U2MT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnJlc3VsdC5mbGFjJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjc0NDIzOTE0fX19XX0_&Signature=jNvGiK2-odtpMh0sYLLW4ynZKu7NVBjD38v1ZySxTEzYvTxikBpknlnsf05BJStGzrqVcZFWxLSYv7YGoVA-XTIUn3KjoYBXmVT7juMM-oyHwKY770x6Y0vwPx~UN0yAF5PZZNsaDgQp4Z2njkynG6H~kniBwtLkfjE8kk-WGqFtDW7UumhYrJfLMrJdgSM9ewxWZArX3GAGSXPqgOyOG53xAutpZeDQW20HkGUV8l5zMz3H2H4VBlyNhkpPcq4v7KBz2dBNO7Qm7FoTnWR24hkq1vpDQsn~zOEBUeF3BSOGoZYWVgZBSpE07-oqrNnLAYwDbByPghx8dFdmzb-QEg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.64.174.43, 18.64.174.106, 18.64.174.110, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.64.174.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 70166 (69K) [audio/flac]\n",
            "Saving to: ‘result.flac’\n",
            "\n",
            "result.flac         100%[===================>]  68.52K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-01-19 21:45:14 (1.35 MB/s) - ‘result.flac’ saved [70166/70166]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "from transformers import (\n",
        "    AutoTokenizer\n",
        ")\n",
        "\n",
        "model_id = \"openai/whisper-tiny\"\n",
        "encoder_model = '/content/exported_onnx_models/openai/whisper-tiny/encoder_model.onnx'\n",
        "decoder_model = '/content/exported_onnx_models/openai/whisper-tiny/decoder_model.onnx'\n",
        "encoder_ort_sess = ort.InferenceSession(encoder_model)\n",
        "decoder_ort_sess = ort.InferenceSession(decoder_model)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "start_tokens = [50258, 50266, 50358, 50363] #<|startoftranscript|><|ja|><|translate|><|notimestamps|>\n",
        "text = transcribe(start_tokens, '/content/result.flac', encoder_ort_sess, decoder_ort_sess, tokenizer, skip_special_tokens=True)\n",
        "text"
      ],
      "metadata": {
        "id": "wROOJjNAAQUD",
        "outputId": "cc8a2cc2-ccd9-43ae-9436-a44645f1d2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I think Kimura-san is a good person.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}